{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c75f7b-479f-413e-99c3-a41c8a65d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the following lines of code to install spacy\n",
    "\n",
    "# !pip install -U pip setuptools wheel\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b88fb4e-8d6e-4e4d-aee6-0d84657a831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e8b693-8ead-42fc-9f8d-6009f44d0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a21a20-c2e5-418c-ac1e-2f03e522ee32",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aba96d5-233f-4f81-9e0b-20dbe0bcedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(s1,s2):\n",
    "    # convert to lowercase\n",
    "    s1 = s1.lower()\n",
    "    s2 = s2.lower()\n",
    "    \n",
    "    # Convert sentences to doc\n",
    "    docs = [nlp(s) for s in [s1,s2]]\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    token1,token2 = [[token.text for token in doc] for doc in docs] \n",
    "    jac =  len(set(token1).intersection(token2)) / len(set(token1).union(token2))\n",
    "    \n",
    "\n",
    "    # Vectorize using word2vector\n",
    "    v1,v2 = [doc.vector for doc in docs]\n",
    "    cos = np.dot(v1,v2) / sum(v1**2)**0.5 / sum(v2**2)**0.5\n",
    "    \n",
    "    # Eucledian distance\n",
    "    euc = e ** -sum((v1-v2)**2)**0.5\n",
    "    \n",
    "    df =  pd.DataFrame([[jac,cos,euc]], index = [\"Similarity\"], columns = [\"Jaccard\", \"Cosine\",\"Eucledian\"]).T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7e5cb-d66c-4d8e-85e6-ec193d120a5a",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "1. Convert texts to lowercase\n",
    "2. Tokenize the texts\n",
    "3. Vectorize the tokens using the word2vector method\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "1. Jaccard : Ratio of number of intersecting words and total number of words\n",
    "2. Cosine : Cos($\\theta$), where $\\theta$ is the angle between the vectors\n",
    "3. Eucledian : $e^{-d}$, where $d$ is the eucledian distance between the vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36eb899-143d-4022-a2a7-ef0a7ec74e37",
   "metadata": {},
   "source": [
    "# Performace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b7d69-fc71-4fc8-b0a6-3976708759ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example 1 : Paraphrased texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea240f8-6ba7-4957-9b67-a59d3149abe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6372549 , 0.99712061, 0.77839407])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7311828 , 0.99622822, 0.75834485])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59756098, 0.99450341, 0.72205203])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine works great,\n",
      "Eucledian is also reliable,\n",
      "Jaccard isn't\n"
     ]
    }
   ],
   "source": [
    "# Paraphrased texts from quilbot\n",
    "print(\"Text 1\")\n",
    "a = \"\"\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\n",
    "So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\"\"\"\n",
    "b = \"\"\"Alice was becoming bored of sitting on the bank with her sister and having nothing to do: she had peered inside the book her sister was reading once or twice, but it was devoid of pictures or discussions, 'and what is the use of a book without pictures or conversation?' Alice wondered. ' \n",
    "So she was debating in her head (as best she could, because the hot day had made her feel drowsy and foolish) whether the pleasure of making a daisy-chain was worth the trouble of getting up and gathering the daisies, when a White Rabbit with pink eyes dashed close by her.\"\"\"\n",
    "display(similarity(a,b))\n",
    "\n",
    "print(\"\\nText 2\")\n",
    "a = \"It was a pleasure to burn.It was a special pleasure to see things eaten, to see things blackened and changed. With the brass nozzle in his fists, with this great python spitting its venomous kerosene upon the world, the blood pounded in his head, and his hands were the hands of some amazing conductor playing all the symphonies of blazing and burning to bring down the tatters and charcoal ruins of history. With his symbolic helmet numbered 451 on his stolid head, and his eyes all orange flame with the thought of what came next, he flicked the igniter and the house jumped up in a gorging fire that burned the evening sky red and yellow and black.\"\n",
    "b = \"It was a lot of fun to burn.It was really satisfying to see things devoured, charred, and transformed. The blood beat in his skull, and his hands were the hands of some fantastic conductor playing all the symphonies of scorching and burning to bring down the tatters and charcoal ruins of history with the brass nozzle in his fists, with this big python spitting its toxic kerosene into the world. He flicked the igniter, and the house jumped up in a gorging fire that burned the evening sky red, yellow, and black. With his symbolic helmet numbered 451 on his stolid head, and his eyes all orange flame with the thought of what came next, he flicked the igniter, and the house jumped up in a gorging fire that burned the evening sky red, yellow, and black.\"\n",
    "display(similarity(a,b))\n",
    "\n",
    "print(\"\\nText 3\")\n",
    "a = \"\"\"ABOUT 13.5 BILLION YEARS AGO, MATTER, energy, time and space came into being in what is known as the Big Bang. The story of these fundamental features of our universe is called physics.\n",
    "About 300,000 years after their appearance, matter and energy started to coalesce into complex structures, called atoms, which then combined into molecules. The story of atoms, molecules and their interactions is called chemistry.\n",
    "About 3.8 billion years ago, on a planet called Earth, certain molecules combined to form particularly large and intricate structures called organisms. The story of organisms is called biology.\"\"\"\n",
    "b = \"\"\"MATTER, ENERGY, TIME, AND SPACE BEGAN ABOUT 13.5 BILLION YEARS AGO in what is known as the Big Bang. Physics is the narrative of these fundamental aspects of our universe. \n",
    "Matter and energy began to consolidate into complex formations called atoms some 300,000 years after they first appeared, which subsequently merged to form molecules. Chemistry is the study of atoms, molecules, and their interactions. \n",
    "3.8 billion years ago, on a planet named Earth, some chemicals came together to form animals, which are especially massive and intricate structures. Biology is the study of living things.\"\"\"\n",
    "display(similarity(a,b))\n",
    "\n",
    "print(\"\\nCosine works great,\\nEucledian is also reliable,\\nJaccard isn't\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc14c0-77ec-4007-b8f4-369286909ec1",
   "metadata": {},
   "source": [
    "### Example 2 : Active vs passive voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9ca6de-6acb-4ed7-8e9b-73d9167f345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cosine</th>\n",
       "      <td>0.929012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eucledian</th>\n",
       "      <td>0.236978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Similarity\n",
       "Jaccard      0.333333\n",
       "Cosine       0.929012\n",
       "Eucledian    0.236978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cosine</th>\n",
       "      <td>0.978416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eucledian</th>\n",
       "      <td>0.470138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Similarity\n",
       "Jaccard      0.800000\n",
       "Cosine       0.978416\n",
       "Eucledian    0.470138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Again, Cosine works really well\n"
     ]
    }
   ],
   "source": [
    "a = \"He is kicking the monkey\"\n",
    "b = \"The monkey is being kicked by him\"\n",
    "display(similarity(a,b))\n",
    "\n",
    "a = \"Mom read the novel in one day.\"\n",
    "b = \"The novel was read by Mom in one day.\"\n",
    "display(similarity(a,b))\n",
    "\n",
    "print(\"Again, Cosine works really well\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce5139-f64f-4fb7-b97c-1b1eb5ac413b",
   "metadata": {},
   "source": [
    "### Limitations : Can't differentiate sentences based on their meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679cf94c-c3a8-4bc0-ae28-d1997cd1d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cosine</th>\n",
       "      <td>0.737367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eucledian</th>\n",
       "      <td>0.049716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Similarity\n",
       "Jaccard      0.100000\n",
       "Cosine       0.737367\n",
       "Eucledian    0.049716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity should not be this high\n"
     ]
    }
   ],
   "source": [
    "a = \"The cat was purring tonight\"\n",
    "b = \"I am going to eat tonight\"\n",
    "display(similarity(a,b))\n",
    "\n",
    "print(\"Cosine similarity should not be this high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965cb15f-3e5b-46e4-9c1c-7d0c5761b3b5",
   "metadata": {},
   "source": [
    "### Furthur Research:\n",
    "\n",
    "1. Contextual Embeddings\n",
    "2. Sentence Transformers (BERT, USE)\n",
    "3. Doc2vector method\n",
    "4. Lemmatization and Stemming\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b50df-f764-496c-ae28-2b2b58d45d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
